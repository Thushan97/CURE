{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNYgCKasjpJ1kYd0K5QmZt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thushan97/CURE/blob/master/gpt_conut_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04b5Y2KlVvaJ",
        "outputId": "5899b04f-f19b-4500-86ff-6efc51666f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CURE' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Thushan97/CURE.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/CURE/* /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf4LBkfjV9pW",
        "outputId": "490e4ddf-8fc6-4ff0-a5db-f8c02f2aaea8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/CURE/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrain model download\n",
        "!wget \"https://zenodo.org/record/7030145/files/models.tar.xz?download=1\" -c -O 'models.tar.xz'\n",
        "!mkdir /content/data/models\n",
        "!tar -xf models.tar.xz\n",
        "!mv /content/models/* /content/data/models/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS6kXFIVXO9J",
        "outputId": "ff70caa2-da89-40e3-dba9-111a40ea9ec1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-12 07:58:52--  https://zenodo.org/record/7030145/files/models.tar.xz?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "mkdir: cannot create directory ‘/content/data/models’: File exists\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==2.10.0 subword-nmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujyExeoEZ6VM",
        "outputId": "17fa3fd7-eb21-4af8-9a78-296de3a522e6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (0.0.53)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (4.64.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (0.1.97)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (2022.6.2)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from subword-nmt) (4.0.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "OiM2X0qPWds0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import codecs\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import OpenAIGPTLMHeadModel\n",
        "\n",
        "GPT_CONUT_TRAINER_DIR = os.path.abspath('/content')#os.path.abspath(__file__)[: os.path.abspath(__file__).rindex('/') + 1]"
      ],
      "metadata": {
        "id": "YNQLj3YJWdTc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models.gpt_conut import GPTCoNuTModel\n",
        "from src.dataloader.dictionary import Dictionary\n",
        "from src.dataloader.gpt_conut_data_loader import GPTCoNuTDataLoader"
      ],
      "metadata": {
        "id": "Ff_GgGKJWWyk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'CUDA GPU availible : {torch.cuda.is_available()}')\n",
        "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "VpeQL1nBWybZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTCoNuTTrainer():\n",
        "    def __init__(self, train_loader, valid_loader, dictionary, gpt_file):\n",
        "        gpt_loaded = torch.load(gpt_file)\n",
        "        config = gpt_loaded['config']\n",
        "        gpt_model = OpenAIGPTLMHeadModel(config).cuda()\n",
        "        gpt_model.load_state_dict(gpt_loaded['model'])\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "        self.valid_loader = valid_loader\n",
        "        self.dictionary = dictionary\n",
        "\n",
        "        self.batch_size = 12\n",
        "        self.load_size = 1200   # load 1200 samples from training data every time\n",
        "\n",
        "        self.gpt_model = gpt_model\n",
        "        self.model = None\n",
        "        self.hyper_parameter = {}\n",
        "        self.optimizer = None\n",
        "        self.current_train_step = 0\n",
        "        self.val_loss = {}\n",
        "\n",
        "    def shuffle_dataset(self):\n",
        "        indices = [i for i in range(len(self.train_loader.dataset))]\n",
        "        random.shuffle(indices)\n",
        "        return indices\n",
        "\n",
        "    def train_step(self, samples):\n",
        "        self.model.train()\n",
        "        self.current_train_step += 1\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        batch = self.train_loader.dataset.collater(samples)\n",
        "        if torch.cuda.is_available():\n",
        "            outputs = self.model(\n",
        "                batch['net_input']['src_tokens'].cuda(),\n",
        "                batch['net_input']['src_with_prev_context'].cuda(),\n",
        "                batch['net_input']['ctx_tokens'].cuda(),\n",
        "                prev_tokens_index=batch['target_index'].cuda(),\n",
        "                prev_tokens_with_context=batch['target_with_prev_context'].cuda(),\n",
        "                labels=batch['target'].cuda(),\n",
        "            )\n",
        "        else:\n",
        "            outputs = self.model(\n",
        "                batch['net_input']['src_tokens'],\n",
        "                batch['net_input']['src_with_prev_context'],\n",
        "                batch['net_input']['ctx_tokens'],\n",
        "                prev_tokens_index=batch['target_index'],\n",
        "                prev_tokens_with_context=batch['target_with_prev_context'],\n",
        "                labels=batch['target'],\n",
        "            )\n",
        "        logits, avg_attn_scores, apr_loss, lm_loss = outputs[:4]\n",
        "        loss = apr_loss + 0.3 * lm_loss\n",
        "        loss.mean().backward()\n",
        "        nn.utils.clip_grad_norm_(self.model.parameters(), 0.5, norm_type=2)\n",
        "        self.optimizer.step()\n",
        "        return loss.mean().item(), apr_loss.mean().item(), lm_loss.mean().item()\n",
        "\n",
        "    def valid_step(self, samples):\n",
        "        self.model.eval()\n",
        "        batch = self.valid_loader.dataset.collater(samples)\n",
        "        outputs = self.model(\n",
        "            batch['net_input']['src_tokens'].cuda(),\n",
        "            batch['net_input']['src_with_prev_context'].cuda(),\n",
        "            batch['net_input']['ctx_tokens'].cuda(),\n",
        "            prev_tokens_index=batch['target_index'].cuda(),\n",
        "            prev_tokens_with_context=batch['target_with_prev_context'].cuda(),\n",
        "            labels=batch['target'].cuda(),\n",
        "        )\n",
        "        logits, avg_attn_scores, apr_loss, lm_loss = outputs[:4]\n",
        "        loss = apr_loss + 0.3 * lm_loss\n",
        "        return loss.mean().item(), apr_loss.mean().item(), lm_loss.mean().item(), logits\n",
        "\n",
        "    def validate_and_save(self, model_id, save_dir):\n",
        "        oom = 0\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_fconv_loss, val_lm_loss = [], [], []\n",
        "            for i in range(0, self.valid_loader.total_size, self.batch_size):\n",
        "                samples = [self.valid_loader.dataset[j]\n",
        "                           for j in range(i, min(len(self.valid_loader.dataset), i + self.batch_size))]\n",
        "                try:\n",
        "                    loss, fconv_loss, lm_loss, logits = self.valid_step(samples)\n",
        "                    val_loss.append(float(loss))\n",
        "                    val_fconv_loss.append(float(fconv_loss))\n",
        "                    val_lm_loss.append(float(lm_loss))\n",
        "                except Exception as e:\n",
        "                    oom += 1\n",
        "\n",
        "            info = 'val loss:{}, val apr_loss:{}, val lm_loss:{}, val ppl:{}, oom:{}'.format(\n",
        "                round(float(np.mean(val_loss)), 6),\n",
        "                round(float(np.mean(val_fconv_loss)), 6),\n",
        "                round(float(np.mean(val_lm_loss)), 6),\n",
        "                round(float(np.exp(np.mean(val_loss))), 6),\n",
        "                oom\n",
        "            )\n",
        "            print(info)\n",
        "\n",
        "            val_loss = np.mean(val_fconv_loss)\n",
        "            checkpoint = {\n",
        "                'model': self.model.state_dict(),\n",
        "                'optimizer': self.optimizer.state_dict(),\n",
        "                'current_step': self.current_train_step,\n",
        "                # 'config': self.model.module.config(),\n",
        "                'val_loss': val_loss,\n",
        "            }\n",
        "            torch.save(checkpoint, save_dir + 'gpt_conut_' + str(model_id) + '.pt')\n",
        "            self.val_loss[model_id] = {\n",
        "                'val_loss': val_loss,\n",
        "                'hyper-parameter': str(self.hyper_parameter),\n",
        "            }\n",
        "\n",
        "        return val_loss\n",
        "\n",
        "    def train(self, model_id, epochs, hyper_parameter, save_dir):\n",
        "        self.hyper_parameter = hyper_parameter\n",
        "        self.model = GPTCoNuTModel(\n",
        "            self.dictionary, embed_dim=384, max_positions=1024,\n",
        "            src_encoder_convolutions=self.hyper_parameter['src_encoder_convolutions'],\n",
        "            ctx_encoder_convolutions=self.hyper_parameter['ctx_encoder_convolutions'],\n",
        "            decoder_convolutions=self.hyper_parameter['decoder_convolutions'],\n",
        "            dropout=self.hyper_parameter['dropout'], embed_model=self.gpt_model,\n",
        "        ).cuda()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=6.25e-5)\n",
        "        # self.model = nn.DataParallel(self.model, device_ids=device_ids)\n",
        "        \n",
        "        self.valid_loader.load_data(0, self.valid_loader.total_size)\n",
        "        for epoch in range(epochs):\n",
        "            start_time = time.time()\n",
        "            for i in range(0, self.train_loader.total_size, self.load_size):\n",
        "                oom = 0\n",
        "                self.train_loader.load_data(i, i + self.load_size)\n",
        "                indices = self.shuffle_dataset()\n",
        "                train_loss, train_apr_loss, train_lm_loss = [], [], []\n",
        "\n",
        "                start, end = 0, 0\n",
        "                samples = []\n",
        "                max_src, max_ctx, max_tgt = 0, 0, 0\n",
        "                while end < len(self.train_loader.dataset):\n",
        "                    sample = self.train_loader.dataset[indices[end]]\n",
        "                    if max_ctx + len(sample['target']) >= 1023 \\\n",
        "                            or max_tgt + len(sample['prev_context']) >= 1023 \\\n",
        "                            or max_ctx + len(sample['source']) >= 1023 \\\n",
        "                            or max_src + len(sample['prev_context']) >= 1023 \\\n",
        "                            or end - start == self.batch_size:\n",
        "                        try:\n",
        "                            loss, apr_loss, lm_loss = self.train_step(samples)\n",
        "                            train_loss.append(loss)\n",
        "                            train_apr_loss.append(apr_loss)\n",
        "                            train_lm_loss.append(lm_loss)\n",
        "                        except Exception as e:\n",
        "                            oom += 1\n",
        "\n",
        "                        start = end\n",
        "                        max_src, max_ctx, max_tgt = 0, 0, 0\n",
        "                        samples = []\n",
        "                        continue\n",
        "                    max_src = max(max_src, len(sample['source']))\n",
        "                    max_ctx = max(max_ctx, len(sample['prev_context']))\n",
        "                    max_tgt = max(max_tgt, len(sample['target']))\n",
        "                    end += 1\n",
        "                    samples.append(sample)\n",
        "                if len(samples) > 0:\n",
        "                    try:\n",
        "                        loss, apr_loss, lm_loss = self.train_step(samples)\n",
        "                        train_loss.append(loss)\n",
        "                        train_apr_loss.append(apr_loss)\n",
        "                        train_lm_loss.append(lm_loss)\n",
        "                    except Exception as e:\n",
        "                        oom += 1\n",
        "\n",
        "                if (i // self.load_size) % 10 == 0:\n",
        "                    info = 'epoch:{}, load data:{}, lr:{}, loss:{}, apr_loss:{}, lm_loss:{}, time:{}s, oom:{}'.\\\n",
        "                        format(epoch + 1, i + self.load_size,\n",
        "                               round(self.optimizer.param_groups[0]['lr'], 10),\n",
        "                               round(float(np.mean(train_loss)), 6),\n",
        "                               round(float(np.mean(train_apr_loss)), 6),\n",
        "                               round(float(np.mean(train_lm_loss)), 6),\n",
        "                               int(time.time() - start_time), oom\n",
        "                               )\n",
        "                    start_time = time.time()\n",
        "                    print(str(model_id) + ' ' + info)\n",
        "\n",
        "                if (i // self.load_size) % 100 == 0:\n",
        "                    self.validate_and_save(model_id, save_dir)\n",
        "        self.validate_and_save(model_id, save_dir)"
      ],
      "metadata": {
        "id": "KffOeTnGW1bG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    device_ids = [0, 1, 2, 3]\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
        "    \n",
        "    vocab_file = GPT_CONUT_TRAINER_DIR + '/data/vocabulary/vocabulary.txt'\n",
        "    train_file = GPT_CONUT_TRAINER_DIR + '/data/data/training_bpe.txt'\n",
        "    valid_file = GPT_CONUT_TRAINER_DIR + '/data/data/validation_bpe.txt'\n",
        "    gpt_file = GPT_CONUT_TRAINER_DIR + '/data/models/code_gpt.pt'\n",
        "\n",
        "    dictionary = Dictionary(vocab_file, min_cnt=0)\n",
        "    print('dictionary initialized, vocab size:{}'.format(len(dictionary)))\n",
        "\n",
        "    train_loader = GPTCoNuTDataLoader(train_file, dictionary)\n",
        "    valid_loader = GPTCoNuTDataLoader(valid_file, dictionary)\n",
        "    print('data loader initialized, train size:{}, validate size:{}'.\n",
        "          format(train_loader.total_size, valid_loader.total_size))\n",
        "\n",
        "    trainer = GPTCoNuTTrainer(train_loader, valid_loader, dictionary, gpt_file)\n",
        "\n",
        "    hyper_parameter = {\n",
        "        'src_encoder_convolutions': ((192, 5),) * 1,\n",
        "        'ctx_encoder_convolutions': ((384, 5),) * 1,\n",
        "        'decoder_convolutions': ((192, 5),) * 1,\n",
        "        'dropout': 0.1,\n",
        "    }\n",
        "    model_id = 1\n",
        "    epochs = 5\n",
        "    trainer.train(model_id, epochs, hyper_parameter, save_dir=GPT_CONUT_TRAINER_DIR + '/data/models/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7doawc2lW8o5",
        "outputId": "30fbbbd6-d78b-446d-b6dc-b5d7ab03dacb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dictionary initialized, vocab size:50061\n",
            "data loader initialized, train size:2000, validate size:100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 epoch:1, load data:1200, lr:6.25e-05, loss:9.608289, apr_loss:7.221054, lm_loss:7.957447, time:54s, oom:44\n",
            "val loss:5.09603, val apr_loss:3.245551, val lm_loss:6.168262, val ppl:163.371957, oom:0\n",
            "1 epoch:2, load data:1200, lr:6.25e-05, loss:3.710341, apr_loss:3.077762, lm_loss:2.108595, time:53s, oom:44\n",
            "val loss:2.526983, val apr_loss:2.283755, val lm_loss:0.81076, val ppl:12.515687, oom:0\n",
            "1 epoch:3, load data:1200, lr:6.25e-05, loss:2.74184, apr_loss:2.456163, lm_loss:0.952255, time:56s, oom:42\n",
            "val loss:1.95275, val apr_loss:1.736616, val lm_loss:0.720448, val ppl:7.048044, oom:0\n",
            "1 epoch:4, load data:1200, lr:6.25e-05, loss:2.106179, apr_loss:1.856535, lm_loss:0.832149, time:55s, oom:47\n",
            "val loss:1.574926, val apr_loss:1.362139, val lm_loss:0.709291, val ppl:4.830386, oom:0\n",
            "1 epoch:5, load data:1200, lr:6.25e-05, loss:1.882184, apr_loss:1.634849, lm_loss:0.824448, time:56s, oom:38\n",
            "val loss:1.398118, val apr_loss:1.191759, val lm_loss:0.687861, val ppl:4.047574, oom:0\n",
            "val loss:1.354288, val apr_loss:1.151968, val lm_loss:0.674402, val ppl:3.874003, oom:0\n"
          ]
        }
      ]
    }
  ]
}
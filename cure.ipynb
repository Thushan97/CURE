{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thushan97/CURE/blob/master/cure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04b5Y2KlVvaJ",
        "outputId": "d573d4aa-c746-4eee-f497-bf61cd636bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CURE'...\n",
            "remote: Enumerating objects: 993, done.\u001b[K\n",
            "remote: Counting objects: 100% (321/321), done.\u001b[K\n",
            "remote: Compressing objects: 100% (278/278), done.\u001b[K\n",
            "remote: Total 993 (delta 41), reused 296 (delta 29), pack-reused 672\u001b[K\n",
            "Receiving objects: 100% (993/993), 79.62 MiB | 13.52 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Thushan97/CURE.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/CURE/* /content/"
      ],
      "metadata": {
        "id": "Lf4LBkfjV9pW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrain model download\n",
        "!wget \"https://zenodo.org/record/7030145/files/models.tar.xz?download=1\" -c -O 'models.tar.xz'\n",
        "!mkdir /content/data/models\n",
        "!tar -xf models.tar.xz\n",
        "!mv /content/models/* /content/data/models/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS6kXFIVXO9J",
        "outputId": "dc72f997-d976-4708-cb43-b9930a51a799"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-12 16:13:16--  https://zenodo.org/record/7030145/files/models.tar.xz?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1911937724 (1.8G) [application/octet-stream]\n",
            "Saving to: ‘models.tar.xz’\n",
            "\n",
            "models.tar.xz       100%[===================>]   1.78G  18.8MB/s    in 98s     \n",
            "\n",
            "2022-09-12 16:14:56 (18.6 MB/s) - ‘models.tar.xz’ saved [1911937724/1911937724]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==2.10.0 subword-nmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujyExeoEZ6VM",
        "outputId": "8db3b83a-e18a-4fa9-b283-76449f2d214e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==2.10.0\n",
            "  Downloading transformers-2.10.0-py3-none-any.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (4.64.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0) (3.8.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=4e9c213f6dcfdb546763210ba4bc9610b09a8fdd7cf4f0e5a708b070bfe17601\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, mock, transformers, subword-nmt\n",
            "Successfully installed mock-4.0.3 sacremoses-0.0.53 sentencepiece-0.1.97 subword-nmt-0.3.8 tokenizers-0.7.0 transformers-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "OiM2X0qPWds0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run gpt_conut_trainer.py file"
      ],
      "metadata": {
        "id": "9NPPvZ58sqY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import codecs\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import OpenAIGPTLMHeadModel\n",
        "\n",
        "GPT_CONUT_TRAINER_DIR = os.path.abspath('/content')#os.path.abspath(__file__)[: os.path.abspath(__file__).rindex('/') + 1]"
      ],
      "metadata": {
        "id": "YNQLj3YJWdTc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models.gpt_conut import GPTCoNuTModel\n",
        "from src.dataloader.dictionary import Dictionary\n",
        "from src.dataloader.gpt_conut_data_loader import GPTCoNuTDataLoader"
      ],
      "metadata": {
        "id": "Ff_GgGKJWWyk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "DyuHj06gvReD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'CUDA GPU availible : {torch.cuda.is_available()}')\n",
        "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "VpeQL1nBWybZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTCoNuTTrainer():\n",
        "    def __init__(self, train_loader, valid_loader, dictionary, gpt_file):\n",
        "        gpt_loaded = torch.load(gpt_file)\n",
        "        config = gpt_loaded['config']\n",
        "        gpt_model = OpenAIGPTLMHeadModel(config).cuda()\n",
        "        gpt_model.load_state_dict(gpt_loaded['model'])\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "        self.valid_loader = valid_loader\n",
        "        self.dictionary = dictionary\n",
        "\n",
        "        self.batch_size = 12\n",
        "        self.load_size = 1200   # load 1200 samples from training data every time\n",
        "\n",
        "        self.gpt_model = gpt_model\n",
        "        self.model = None\n",
        "        self.hyper_parameter = {}\n",
        "        self.optimizer = None\n",
        "        self.current_train_step = 0\n",
        "        self.val_loss = {}\n",
        "\n",
        "    def shuffle_dataset(self):\n",
        "        indices = [i for i in range(len(self.train_loader.dataset))]\n",
        "        random.shuffle(indices)\n",
        "        return indices\n",
        "\n",
        "    def train_step(self, samples):\n",
        "        self.model.train()\n",
        "        self.current_train_step += 1\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        batch = self.train_loader.dataset.collater(samples)\n",
        "        if torch.cuda.is_available():\n",
        "            outputs = self.model(\n",
        "                batch['net_input']['src_tokens'].cuda(),\n",
        "                batch['net_input']['src_with_prev_context'].cuda(),\n",
        "                batch['net_input']['ctx_tokens'].cuda(),\n",
        "                prev_tokens_index=batch['target_index'].cuda(),\n",
        "                prev_tokens_with_context=batch['target_with_prev_context'].cuda(),\n",
        "                labels=batch['target'].cuda(),\n",
        "            )\n",
        "        else:\n",
        "            outputs = self.model(\n",
        "                batch['net_input']['src_tokens'],\n",
        "                batch['net_input']['src_with_prev_context'],\n",
        "                batch['net_input']['ctx_tokens'],\n",
        "                prev_tokens_index=batch['target_index'],\n",
        "                prev_tokens_with_context=batch['target_with_prev_context'],\n",
        "                labels=batch['target'],\n",
        "            )\n",
        "        logits, avg_attn_scores, apr_loss, lm_loss = outputs[:4]\n",
        "        loss = apr_loss + 0.3 * lm_loss\n",
        "        loss.mean().backward()\n",
        "        nn.utils.clip_grad_norm_(self.model.parameters(), 0.5, norm_type=2)\n",
        "        self.optimizer.step()\n",
        "        return loss.mean().item(), apr_loss.mean().item(), lm_loss.mean().item()\n",
        "\n",
        "    def valid_step(self, samples):\n",
        "        self.model.eval()\n",
        "        batch = self.valid_loader.dataset.collater(samples)\n",
        "        outputs = self.model(\n",
        "            batch['net_input']['src_tokens'].cuda(),\n",
        "            batch['net_input']['src_with_prev_context'].cuda(),\n",
        "            batch['net_input']['ctx_tokens'].cuda(),\n",
        "            prev_tokens_index=batch['target_index'].cuda(),\n",
        "            prev_tokens_with_context=batch['target_with_prev_context'].cuda(),\n",
        "            labels=batch['target'].cuda(),\n",
        "        )\n",
        "        logits, avg_attn_scores, apr_loss, lm_loss = outputs[:4]\n",
        "        loss = apr_loss + 0.3 * lm_loss\n",
        "        return loss.mean().item(), apr_loss.mean().item(), lm_loss.mean().item(), logits\n",
        "\n",
        "    def validate_and_save(self, model_id, save_dir):\n",
        "        oom = 0\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_fconv_loss, val_lm_loss = [], [], []\n",
        "            for i in range(0, self.valid_loader.total_size, self.batch_size):\n",
        "                samples = [self.valid_loader.dataset[j]\n",
        "                           for j in range(i, min(len(self.valid_loader.dataset), i + self.batch_size))]\n",
        "                try:\n",
        "                    loss, fconv_loss, lm_loss, logits = self.valid_step(samples)\n",
        "                    val_loss.append(float(loss))\n",
        "                    val_fconv_loss.append(float(fconv_loss))\n",
        "                    val_lm_loss.append(float(lm_loss))\n",
        "                except Exception as e:\n",
        "                    oom += 1\n",
        "\n",
        "            info = 'val loss:{}, val apr_loss:{}, val lm_loss:{}, val ppl:{}, oom:{}'.format(\n",
        "                round(float(np.mean(val_loss)), 6),\n",
        "                round(float(np.mean(val_fconv_loss)), 6),\n",
        "                round(float(np.mean(val_lm_loss)), 6),\n",
        "                round(float(np.exp(np.mean(val_loss))), 6),\n",
        "                oom\n",
        "            )\n",
        "            print(info)\n",
        "\n",
        "            val_loss = np.mean(val_fconv_loss)\n",
        "            checkpoint = {\n",
        "                'model': self.model.state_dict(),\n",
        "                'optimizer': self.optimizer.state_dict(),\n",
        "                'current_step': self.current_train_step,\n",
        "                'config': self.model.config(),\n",
        "                'val_loss': val_loss,\n",
        "            }\n",
        "            torch.save(checkpoint, save_dir + 'gpt_conut_' + str(model_id) + '.pt')\n",
        "            self.val_loss[model_id] = {\n",
        "                'val_loss': val_loss,\n",
        "                'hyper-parameter': str(self.hyper_parameter),\n",
        "            }\n",
        "\n",
        "        return val_loss\n",
        "\n",
        "    def train(self, model_id, epochs, hyper_parameter, save_dir):\n",
        "        self.hyper_parameter = hyper_parameter\n",
        "        self.model = GPTCoNuTModel(\n",
        "            self.dictionary, embed_dim=384, max_positions=1024,\n",
        "            src_encoder_convolutions=self.hyper_parameter['src_encoder_convolutions'],\n",
        "            ctx_encoder_convolutions=self.hyper_parameter['ctx_encoder_convolutions'],\n",
        "            decoder_convolutions=self.hyper_parameter['decoder_convolutions'],\n",
        "            dropout=self.hyper_parameter['dropout'], embed_model=self.gpt_model,\n",
        "        ).cuda()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=6.25e-5)\n",
        "        # self.model = nn.DataParallel(self.model, device_ids=device_ids)\n",
        "        \n",
        "        self.valid_loader.load_data(0, self.valid_loader.total_size)\n",
        "        for epoch in range(epochs):\n",
        "            start_time = time.time()\n",
        "            for i in range(0, self.train_loader.total_size, self.load_size):\n",
        "                oom = 0\n",
        "                self.train_loader.load_data(i, i + self.load_size)\n",
        "                indices = self.shuffle_dataset()\n",
        "                train_loss, train_apr_loss, train_lm_loss = [], [], []\n",
        "\n",
        "                start, end = 0, 0\n",
        "                samples = []\n",
        "                max_src, max_ctx, max_tgt = 0, 0, 0\n",
        "                while end < len(self.train_loader.dataset):\n",
        "                    sample = self.train_loader.dataset[indices[end]]\n",
        "                    if max_ctx + len(sample['target']) >= 1023 \\\n",
        "                            or max_tgt + len(sample['prev_context']) >= 1023 \\\n",
        "                            or max_ctx + len(sample['source']) >= 1023 \\\n",
        "                            or max_src + len(sample['prev_context']) >= 1023 \\\n",
        "                            or end - start == self.batch_size:\n",
        "                        try:\n",
        "                            loss, apr_loss, lm_loss = self.train_step(samples)\n",
        "                            train_loss.append(loss)\n",
        "                            train_apr_loss.append(apr_loss)\n",
        "                            train_lm_loss.append(lm_loss)\n",
        "                        except Exception as e:\n",
        "                            oom += 1\n",
        "\n",
        "                        start = end\n",
        "                        max_src, max_ctx, max_tgt = 0, 0, 0\n",
        "                        samples = []\n",
        "                        continue\n",
        "                    max_src = max(max_src, len(sample['source']))\n",
        "                    max_ctx = max(max_ctx, len(sample['prev_context']))\n",
        "                    max_tgt = max(max_tgt, len(sample['target']))\n",
        "                    end += 1\n",
        "                    samples.append(sample)\n",
        "                if len(samples) > 0:\n",
        "                    try:\n",
        "                        loss, apr_loss, lm_loss = self.train_step(samples)\n",
        "                        train_loss.append(loss)\n",
        "                        train_apr_loss.append(apr_loss)\n",
        "                        train_lm_loss.append(lm_loss)\n",
        "                    except Exception as e:\n",
        "                        oom += 1\n",
        "\n",
        "                if (i // self.load_size) % 10 == 0:\n",
        "                    info = 'epoch:{}, load data:{}, lr:{}, loss:{}, apr_loss:{}, lm_loss:{}, time:{}s, oom:{}'.\\\n",
        "                        format(epoch + 1, i + self.load_size,\n",
        "                               round(self.optimizer.param_groups[0]['lr'], 10),\n",
        "                               round(float(np.mean(train_loss)), 6),\n",
        "                               round(float(np.mean(train_apr_loss)), 6),\n",
        "                               round(float(np.mean(train_lm_loss)), 6),\n",
        "                               int(time.time() - start_time), oom\n",
        "                               )\n",
        "                    start_time = time.time()\n",
        "                    print(str(model_id) + ' ' + info)\n",
        "\n",
        "                if (i // self.load_size) % 100 == 0:\n",
        "                    self.validate_and_save(model_id, save_dir)\n",
        "        self.validate_and_save(model_id, save_dir)"
      ],
      "metadata": {
        "id": "KffOeTnGW1bG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    device_ids = [0, 1, 2, 3]\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
        "    \n",
        "    vocab_file = GPT_CONUT_TRAINER_DIR + '/data/vocabulary/vocabulary.txt'\n",
        "    train_file = GPT_CONUT_TRAINER_DIR + '/data/data/training_bpe.txt'\n",
        "    valid_file = GPT_CONUT_TRAINER_DIR + '/data/data/validation_bpe.txt'\n",
        "    gpt_file = GPT_CONUT_TRAINER_DIR + '/data/models/code_gpt.pt'\n",
        "\n",
        "    dictionary = Dictionary(vocab_file, min_cnt=0)\n",
        "    print('dictionary initialized, vocab size:{}'.format(len(dictionary)))\n",
        "\n",
        "    train_loader = GPTCoNuTDataLoader(train_file, dictionary)\n",
        "    valid_loader = GPTCoNuTDataLoader(valid_file, dictionary)\n",
        "    print('data loader initialized, train size:{}, validate size:{}'.\n",
        "          format(train_loader.total_size, valid_loader.total_size))\n",
        "\n",
        "    trainer = GPTCoNuTTrainer(train_loader, valid_loader, dictionary, gpt_file)\n",
        "\n",
        "    hyper_parameter = {\n",
        "        'src_encoder_convolutions': ((192, 5),) * 1,\n",
        "        'ctx_encoder_convolutions': ((384, 5),) * 1,\n",
        "        'decoder_convolutions': ((192, 5),) * 1,\n",
        "        'dropout': 0.1,\n",
        "    }\n",
        "    model_id = 1\n",
        "    epochs = 5\n",
        "    trainer.train(model_id, epochs, hyper_parameter, save_dir=GPT_CONUT_TRAINER_DIR + '/data/models/')"
      ],
      "metadata": {
        "id": "7doawc2lW8o5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d0e1dc-2ae4-4a0e-9e31-a1cf82a8717a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dictionary initialized, vocab size:50061\n",
            "data loader initialized, train size:2000, validate size:100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 epoch:1, load data:1200, lr:6.25e-05, loss:8.735597, apr_loss:6.386846, lm_loss:7.829169, time:64s, oom:29\n",
            "val loss:4.874268, val apr_loss:3.183986, val lm_loss:5.634272, val ppl:130.878322, oom:0\n",
            "1 epoch:2, load data:1200, lr:6.25e-05, loss:3.228787, apr_loss:2.85313, lm_loss:1.25219, time:67s, oom:32\n",
            "val loss:2.211932, val apr_loss:1.991149, val lm_loss:0.735943, val ppl:9.133347, oom:0\n",
            "1 epoch:3, load data:1200, lr:6.25e-05, loss:2.33018, apr_loss:2.082891, lm_loss:0.824297, time:71s, oom:31\n",
            "val loss:1.608005, val apr_loss:1.399887, val lm_loss:0.693729, val ppl:4.992843, oom:0\n",
            "1 epoch:4, load data:1200, lr:6.25e-05, loss:1.739904, apr_loss:1.508892, lm_loss:0.770041, time:68s, oom:31\n",
            "val loss:1.339282, val apr_loss:1.138002, val lm_loss:0.670933, val ppl:3.816302, oom:0\n",
            "1 epoch:5, load data:1200, lr:6.25e-05, loss:1.618984, apr_loss:1.381005, lm_loss:0.793266, time:64s, oom:32\n",
            "val loss:1.210739, val apr_loss:1.009735, val lm_loss:0.670015, val ppl:3.355964, oom:0\n",
            "val loss:1.17759, val apr_loss:0.981692, val lm_loss:0.652991, val ppl:3.24654, oom:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run gpt_fconv_trainer.py file"
      ],
      "metadata": {
        "id": "hDGLIYMss1kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import codecs\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import OpenAIGPTLMHeadModel\n",
        "\n",
        "# GPT_FCONV_TRAINER_DIR = os.path.abspath(__file__)[: os.path.abspath(__file__).rindex('/') + 1]\n",
        "GPT_FCONV_TRAINER_DIR = os.path.abspath('/content')\n",
        "\n",
        "from src.models.gpt_fconv import GPTFConvModel\n",
        "from src.dataloader.dictionary import Dictionary\n",
        "from src.dataloader.gpt_fconv_data_loader import GPTFConvDataLoader\n",
        "\n",
        "\n",
        "class GPTFConvTrainer():\n",
        "    def __init__(self, train_loader, valid_loader, dictionary, gpt_file):\n",
        "        gpt_loaded = torch.load(gpt_file)\n",
        "        config = gpt_loaded['config']\n",
        "        gpt_model = OpenAIGPTLMHeadModel(config).cuda()\n",
        "        gpt_model.load_state_dict(gpt_loaded['model'])\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "        self.valid_loader = valid_loader\n",
        "        self.dictionary = dictionary\n",
        "\n",
        "        self.batch_size = 12\n",
        "        self.load_size = 1200\n",
        "\n",
        "        self.gpt_model = gpt_model\n",
        "        self.model = None\n",
        "        self.hyper_parameter = {}\n",
        "        self.hyper_parameter_set = {'{}'}\n",
        "        self.optimizer = None\n",
        "        self.current_train_step = 0\n",
        "        self.val_loss = {}\n",
        "\n",
        "    def shuffle_dataset(self):\n",
        "        indices = [i for i in range(len(self.train_loader.dataset))]\n",
        "        random.shuffle(indices)\n",
        "        return indices\n",
        "\n",
        "    def train_step(self, samples):\n",
        "        self.model.train()\n",
        "        self.current_train_step += 1\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        batch = self.train_loader.dataset.collater(samples)\n",
        "        if torch.cuda.is_available():\n",
        "            outputs = self.model(\n",
        "                batch['net_input']['src_tokens'].cuda(),\n",
        "                batch['net_input']['src_with_prev_context'].cuda(),\n",
        "                prev_tokens_index=batch['target_index'].cuda(),\n",
        "                prev_tokens_with_context=batch['target_with_prev_context'].cuda(),\n",
        "                labels=batch['target'].cuda(),\n",
        "            )\n",
        "\n",
        "        logits, avg_attn_scores, apr_loss, lm_loss = outputs[:4]\n",
        "        loss = apr_loss + 0.3 * lm_loss\n",
        "        loss.mean().backward()\n",
        "        nn.utils.clip_grad_norm_(self.model.parameters(), 0.5, norm_type=2)\n",
        "        self.optimizer.step()\n",
        "        return loss.mean().item(), apr_loss.mean().item(), lm_loss.mean().item()\n",
        "\n",
        "    def valid_step(self, samples):\n",
        "        self.model.eval()\n",
        "        batch = self.valid_loader.dataset.collater(samples)\n",
        "        outputs = self.model(\n",
        "            batch['net_input']['src_tokens'].cuda(),\n",
        "            batch['net_input']['src_with_prev_context'].cuda(),\n",
        "            prev_tokens_index=batch['target_index'].cuda(),\n",
        "            prev_tokens_with_context=batch['target_with_prev_context'].cuda(),\n",
        "            labels=batch['target'].cuda(),\n",
        "        )\n",
        "        logits, avg_attn_scores, apr_loss, lm_loss = outputs[:4]\n",
        "        loss = apr_loss + 0.3 * lm_loss\n",
        "        return loss.mean().item(), apr_loss.mean().item(), lm_loss.mean().item(), logits\n",
        "\n",
        "    def validate_and_save(self, model_id, save_dir):\n",
        "        oom = 0\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_fconv_loss, val_lm_loss = [], [], []\n",
        "            for i in range(0, self.valid_loader.total_size, self.batch_size):\n",
        "                samples = [self.valid_loader.dataset[j]\n",
        "                           for j in range(i, min(len(self.valid_loader.dataset), i + self.batch_size))]\n",
        "                try:\n",
        "                    loss, fconv_loss, lm_loss, logits = self.valid_step(samples)\n",
        "                    val_loss.append(float(loss))\n",
        "                    val_fconv_loss.append(float(fconv_loss))\n",
        "                    val_lm_loss.append(float(lm_loss))\n",
        "                except Exception as e:\n",
        "                    oom += 1\n",
        "\n",
        "            info = 'val loss:{}, val apr_loss:{}, val lm_loss:{}, val ppl:{}, oom:{}'.format(\n",
        "                round(float(np.mean(val_loss)), 6),\n",
        "                round(float(np.mean(val_fconv_loss)), 6),\n",
        "                round(float(np.mean(val_lm_loss)), 6),\n",
        "                round(float(np.exp(np.mean(val_loss))), 6),\n",
        "                oom\n",
        "            )\n",
        "            print(info)\n",
        "\n",
        "            val_loss = np.mean(val_fconv_loss)\n",
        "            checkpoint = {\n",
        "                'model': self.model.state_dict(),\n",
        "                'optimizer': self.optimizer.state_dict(),\n",
        "                'current_step': self.current_train_step,\n",
        "                'config': self.model.config(),\n",
        "                'val_loss': val_loss,\n",
        "            }\n",
        "            torch.save(checkpoint, save_dir + 'gpt_fconv_' + str(model_id) + '.pt')\n",
        "            self.val_loss[model_id] = {\n",
        "                'val_loss': val_loss,\n",
        "                'hyper-parameter': str(self.hyper_parameter),\n",
        "            }\n",
        "        return val_loss\n",
        "\n",
        "    def train(self, model_id, epochs, hyper_parameter, save_dir):\n",
        "        self.hyper_parameter = hyper_parameter\n",
        "        self.model = GPTFConvModel(\n",
        "                self.dictionary, embed_dim=384, max_positions=1024,\n",
        "                encoder_convolutions=self.hyper_parameter['encoder_convolutions'],\n",
        "                decoder_convolutions=self.hyper_parameter['decoder_convolutions'],\n",
        "                dropout=self.hyper_parameter['dropout'], embed_model=self.gpt_model,\n",
        "            ).cuda()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=6.25e-5)\n",
        "        # self.model = nn.DataParallel(self.model, device_ids=device_ids)\n",
        "        \n",
        "        self.valid_loader.load_data(0, self.valid_loader.total_size)\n",
        "        for epoch in range(epochs):\n",
        "            start_time = time.time()\n",
        "            for i in range(0, self.train_loader.total_size, self.load_size):\n",
        "                oom = 0\n",
        "                self.train_loader.load_data(i, i + self.load_size)\n",
        "                indices = self.shuffle_dataset()\n",
        "                train_loss, train_apr_loss, train_lm_loss = [], [], []\n",
        "\n",
        "                start, end = 0, 0\n",
        "                samples = []\n",
        "                max_src, max_ctx, max_tgt = 0, 0, 0\n",
        "                while end < len(self.train_loader.dataset):\n",
        "                    sample = self.train_loader.dataset[indices[end]]\n",
        "                    if max_ctx + len(sample['target']) >= 1023 \\\n",
        "                            or max_tgt + len(sample['prev_context']) >= 1023 \\\n",
        "                            or max_ctx + len(sample['source']) >= 1023 \\\n",
        "                            or max_src + len(sample['prev_context']) >= 1023 \\\n",
        "                            or end - start == self.batch_size:\n",
        "                        try:\n",
        "                            loss, apr_loss, lm_loss = self.train_step(samples)\n",
        "                            train_loss.append(loss)\n",
        "                            train_apr_loss.append(apr_loss)\n",
        "                            train_lm_loss.append(lm_loss)\n",
        "                        except Exception as e:\n",
        "                            oom += 1\n",
        "\n",
        "                        start = end\n",
        "                        max_src, max_ctx, max_tgt = 0, 0, 0\n",
        "                        samples = []\n",
        "                        continue\n",
        "                    max_src = max(max_src, len(sample['source']))\n",
        "                    max_ctx = max(max_ctx, len(sample['prev_context']))\n",
        "                    max_tgt = max(max_tgt, len(sample['target']))\n",
        "                    end += 1\n",
        "                    samples.append(sample)\n",
        "                if len(samples) > 0:\n",
        "                    try:\n",
        "                        loss, apr_loss, lm_loss = self.train_step(samples)\n",
        "                        train_loss.append(loss)\n",
        "                        train_apr_loss.append(apr_loss)\n",
        "                        train_lm_loss.append(lm_loss)\n",
        "                    except Exception as e:\n",
        "                        oom += 1\n",
        "\n",
        "                if (i // self.load_size) % 10 == 0:\n",
        "                    info = 'epoch:{}, load data:{}, lr:{}, loss:{}, apr_loss:{}, lm_loss:{}, time:{}s, oom:{}'.\\\n",
        "                        format(epoch + 1, i + self.load_size,\n",
        "                               round(self.optimizer.param_groups[0]['lr'], 10),\n",
        "                               round(float(np.mean(train_loss)), 6),\n",
        "                               round(float(np.mean(train_apr_loss)), 6),\n",
        "                               round(float(np.mean(train_lm_loss)), 6),\n",
        "                               int(time.time() - start_time), oom\n",
        "                               )\n",
        "                    start_time = time.time()\n",
        "                    print(str(model_id) + ' ' + info)\n",
        "\n",
        "                if (i // self.load_size) % 100 == 0:\n",
        "                    self.validate_and_save(model_id, save_dir)\n",
        "        self.validate_and_save(model_id, save_dir)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device_ids = [0, 1, 2, 3]\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
        "    \n",
        "    vocab_file = GPT_FCONV_TRAINER_DIR + '/data/vocabulary/vocabulary.txt'\n",
        "    train_file = GPT_FCONV_TRAINER_DIR + '/data/data/training_bpe.txt'\n",
        "    valid_file = GPT_FCONV_TRAINER_DIR + '/data/data/validation_bpe.txt'\n",
        "    gpt_file = GPT_FCONV_TRAINER_DIR + '/data/models/code_gpt.pt'\n",
        "\n",
        "    dictionary = Dictionary(vocab_file, min_cnt=0)\n",
        "    print('dictionary initialized, vocab size:{}'.format(len(dictionary)))\n",
        "\n",
        "    train_loader = GPTFConvDataLoader(train_file, dictionary)\n",
        "    valid_loader = GPTFConvDataLoader(valid_file, dictionary)\n",
        "    print('data loader initialized, train size:{}, validate size:{}'.\n",
        "          format(train_loader.total_size, valid_loader.total_size))\n",
        "\n",
        "    trainer = GPTFConvTrainer(train_loader, valid_loader, dictionary, gpt_file)\n",
        "\n",
        "    hyper_parameter = {\n",
        "        'encoder_convolutions': ((192, 5),) * 1,\n",
        "        'decoder_convolutions': ((192, 5),) * 1,\n",
        "        'dropout': 0.1,\n",
        "    }\n",
        "    trainer.train(1, 2, hyper_parameter, save_dir=GPT_FCONV_TRAINER_DIR + '/data/models/')\n"
      ],
      "metadata": {
        "id": "JDCQxfDh4pXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d19089-e2f2-44d5-e83f-726b6c6ea943"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dictionary initialized, vocab size:50061\n",
            "data loader initialized, train size:2000, validate size:100\n",
            "1 epoch:1, load data:1200, lr:6.25e-05, loss:7.66629, apr_loss:5.715425, lm_loss:6.502883, time:58s, oom:11\n",
            "val loss:3.377558, val apr_loss:2.772695, val lm_loss:2.016212, val ppl:29.299143, oom:0\n",
            "1 epoch:2, load data:1200, lr:6.25e-05, loss:2.690209, apr_loss:2.43733, lm_loss:0.84293, time:58s, oom:14\n",
            "val loss:1.790417, val apr_loss:1.565059, val lm_loss:0.751193, val ppl:5.99195, oom:0\n",
            "val loss:1.634144, val apr_loss:1.415862, val lm_loss:0.727607, val ppl:5.125069, oom:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run generator.py file"
      ],
      "metadata": {
        "id": "mvFxGHgos-t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from transformers import OpenAIGPTLMHeadModel\n",
        "\n",
        "# GENERATOR_DIR = os.path.abspath(__file__)[: os.path.abspath(__file__).rindex('/') + 1]\n",
        "GENERATOR_DIR = os.path.abspath('/content')\n",
        "# sys.path.append(GENERATOR_DIR + '/models/')\n",
        "# sys.path.append(GENERATOR_DIR + '/dataloader/')\n",
        "# sys.path.append(GENERATOR_DIR + '/tester/')\n",
        "from src.dataloader.gpt_conut_data_loader import GPTCoNuTDataLoader\n",
        "from src.dataloader.gpt_fconv_data_loader import GPTFConvDataLoader\n",
        "from src.dataloader.identifier_data_loader import IdentifierDataLoader\n",
        "from src.dataloader.dictionary import Dictionary\n",
        "from src.models.gpt_conut import GPTCoNuTModel\n",
        "from src.models.gpt_fconv import GPTFConvModel\n",
        "from src.tester.beamsearch import BeamSearch\n",
        "\n",
        "\n",
        "class Generator():\n",
        "    def __init__(self, model, dictionary, data_loader, beam_size=10):\n",
        "        self.model = model\n",
        "        self.dictionary = dictionary\n",
        "        self.data_loader = data_loader\n",
        "        self.beam_size = beam_size\n",
        "        self.beamsearch = BeamSearch(model, dictionary, beam_size)\n",
        "        print(self.model, beam_size)\n",
        "\n",
        "    def generate(self, output_path):\n",
        "        wp = codecs.open(output_path, 'w', 'utf-8')\n",
        "        self.data_loader.load_data(0, self.data_loader.total_size)\n",
        "        for i in range(self.data_loader.total_size):\n",
        "            print(i, '/', self.data_loader.total_size)\n",
        "            data = self.data_loader.dataset[i]\n",
        "            if True:\n",
        "                self.beamsearch.beam_size = self.beam_size\n",
        "                sample = self.data_loader.dataset.collater([data])\n",
        "                with torch.no_grad():\n",
        "                    if isinstance(self.model, GPTCoNuTModel):\n",
        "                        hypothesis = self.beamsearch.generate_gpt_conut(sample)\n",
        "                    elif isinstance(self.model, GPTFConvModel):\n",
        "                        hypothesis = self.beamsearch.generate_gpt_fconv(sample)\n",
        "            # except Exception as e:\n",
        "            #    print(e)\n",
        "            #    continue\n",
        "            id = str(sample['id'].item())\n",
        "            wp.write('S-{}\\t'.format(id))\n",
        "            wp.write(self.dictionary.string(data['source']) + '\\n')\n",
        "            wp.write('T-{}\\t'.format(id))\n",
        "            wp.write(self.dictionary.string(data['target']) + '\\n')\n",
        "            for h in hypothesis:\n",
        "                wp.write('H-{}\\t{}\\t'.format(id, str(h['final_score'])))\n",
        "                wp.write(self.dictionary.string(h['hypo']) + '\\n')\n",
        "                wp.write('P-{}\\t'.format(id))\n",
        "                wp.write(' '.join(str(round(s.item(), 4)) for s in h['score']) + '\\n')\n",
        "        wp.close()\n",
        "\n",
        "\n",
        "def generate_gpt_conut(vocab_file, model_file, input_file, identifier_txt_file, identifier_token_file, output_file, beam_size):\n",
        "    dictionary = Dictionary(vocab_file, min_cnt=0)\n",
        "    print(len(dictionary))\n",
        "    loaded = torch.load(model_file, map_location='cpu')\n",
        "    config = loaded['config']\n",
        "    gpt_config = config['embed_model_config']\n",
        "    gpt_config.attn_pdrop = 0\n",
        "    gpt_config.embd_pdrop = 0\n",
        "    gpt_config.resid_pdrop = 0\n",
        "    gpt_model = OpenAIGPTLMHeadModel(gpt_config)\n",
        "    model = GPTCoNuTModel(\n",
        "        dictionary=dictionary, embed_dim=config['embed_dim'],\n",
        "        max_positions=config['max_positions'],\n",
        "        src_encoder_convolutions=config['src_encoder_convolutions'],\n",
        "        ctx_encoder_convolutions=config['ctx_encoder_convolutions'],\n",
        "        decoder_convolutions=config['decoder_convolutions'],\n",
        "        dropout=0, embed_model=gpt_model,\n",
        "    )\n",
        "\n",
        "    model.load_state_dict(loaded['model'])\n",
        "    identifier_loader = IdentifierDataLoader(\n",
        "        dictionary, identifier_token_file, identifier_txt_file\n",
        "    )\n",
        "    data_loader = GPTCoNuTDataLoader(\n",
        "        input_file, dictionary,\n",
        "        identifier_loader=identifier_loader\n",
        "    )\n",
        "    generator = Generator(model, dictionary, data_loader, beam_size=beam_size)\n",
        "    print('start generate')\n",
        "    generator.generate(output_file)\n",
        "\n",
        "\n",
        "def generate_gpt_fconv(vocab_file, model_file, input_file, identifier_txt_file, identifier_token_file, output_file, beam_size):\n",
        "    dictionary = Dictionary(vocab_file, min_cnt=0)\n",
        "    print(len(dictionary))\n",
        "    loaded = torch.load(\n",
        "        model_file, map_location='cpu'\n",
        "    )\n",
        "    config = loaded['config']\n",
        "    gpt_config = config['embed_model_config']\n",
        "    gpt_config.attn_pdrop = 0\n",
        "    gpt_config.embd_pdrop = 0\n",
        "    gpt_config.resid_pdrop = 0\n",
        "    gpt_model = OpenAIGPTLMHeadModel(gpt_config)\n",
        "    model = GPTFConvModel(\n",
        "        dictionary=dictionary, embed_dim=config['embed_dim'],\n",
        "        max_positions=config['max_positions'],\n",
        "        encoder_convolutions=config['encoder_convolutions'],\n",
        "        decoder_convolutions=config['decoder_convolutions'],\n",
        "        dropout=0, embed_model=gpt_model,\n",
        "    )\n",
        "    model.load_state_dict(loaded['model'])\n",
        "    identifier_loader = IdentifierDataLoader(\n",
        "        dictionary, identifier_token_file, identifier_txt_file\n",
        "    )\n",
        "    data_loader = GPTFConvDataLoader(\n",
        "        input_file, dictionary,\n",
        "        identifier_loader=identifier_loader\n",
        "    )\n",
        "    generator = Generator(model, dictionary, data_loader, beam_size=beam_size)\n",
        "    print('start generate')\n",
        "    generator.generate(output_file)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    vocab_file = GENERATOR_DIR + '/data/vocabulary/vocabulary.txt'\n",
        "    input_file = GENERATOR_DIR + '/candidate_patches/QuixBugs/quixbugs_bpe.txt'\n",
        "    identifier_txt_file = GENERATOR_DIR + '/candidate_patches/QuixBugs/identifier.txt'\n",
        "    identifier_token_file = GENERATOR_DIR + '/candidate_patches/QuixBugs/identifier.tokens'\n",
        "    beam_size = 1000\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "\n",
        "    model_file = GENERATOR_DIR + '/data/models/gpt_fconv_1.pt'\n",
        "    output_file = GENERATOR_DIR + '/data/patches/gpt_fconv_1.txt'\n",
        "    generate_gpt_fconv(vocab_file, model_file, input_file, identifier_txt_file, identifier_token_file, output_file, beam_size)\n",
        "\n",
        "    model_file = GENERATOR_DIR + '/data/models/gpt_conut_1.pt'\n",
        "    output_file = GENERATOR_DIR + '/data/patches/gpt_conut_1.txt'\n",
        "    generate_gpt_conut(vocab_file, model_file, input_file, identifier_txt_file, identifier_token_file, output_file, beam_size)\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "ZaRpLCXstEU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a56ccc1-f415-46dc-e5c8-0bb870773a79"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50061\n",
            "GPTFConvModel(\n",
            "  (embed_model): OpenAIGPTLMHeadModel(\n",
            "    (transformer): OpenAIGPTModel(\n",
            "      (tokens_embed): Embedding(50061, 384)\n",
            "      (positions_embed): Embedding(1024, 384)\n",
            "      (drop): Dropout(p=0, inplace=False)\n",
            "      (h): ModuleList(\n",
            "        (0): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (6): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (7): Block(\n",
            "          (attn): Attention(\n",
            "            (c_attn): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (attn_dropout): Dropout(p=0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Conv1D()\n",
            "            (c_proj): Conv1D()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (lm_head): Linear(in_features=384, out_features=50061, bias=False)\n",
            "  )\n",
            "  (encoder): GPTFConvEncoder(\n",
            "    (embed_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    (fc1): Linear(in_features=384, out_features=192, bias=True)\n",
            "    (convolutions): ModuleList(\n",
            "      (0): ConvTBC()\n",
            "    )\n",
            "    (attentions): ModuleList(\n",
            "      (0): AttentionLayer(\n",
            "        (in_projection): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (out_projection): Linear(in_features=192, out_features=192, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (norms): ModuleList(\n",
            "      (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (fc2): Linear(in_features=192, out_features=384, bias=True)\n",
            "  )\n",
            "  (decoder): GPTFConvDecoder(\n",
            "    (embed_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    (fc1): Linear(in_features=384, out_features=192, bias=True)\n",
            "    (convolutions): ModuleList(\n",
            "      (0): ConvTBC()\n",
            "    )\n",
            "    (attentions): ModuleList(\n",
            "      (0): AttentionLayer(\n",
            "        (in_projection): Linear(in_features=192, out_features=384, bias=True)\n",
            "        (out_projection): Linear(in_features=384, out_features=192, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (norms): ModuleList(\n",
            "      (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (fcg): Linear(in_features=576, out_features=1, bias=True)\n",
            "    (fc2): Linear(in_features=192, out_features=50061, bias=True)\n",
            "  )\n",
            ") 1000\n",
            "start generate\n",
            "0 / 39\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5d965534b38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGENERATOR_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/models/gpt_fconv_1.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGENERATOR_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/patches/gpt_fconv_1.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mgenerate_gpt_fconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifier_txt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifier_token_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGENERATOR_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/models/gpt_conut_1.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-5d965534b38b>\u001b[0m in \u001b[0;36mgenerate_gpt_fconv\u001b[0;34m(vocab_file, model_file, input_file, identifier_txt_file, identifier_token_file, output_file, beam_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start generate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-5d965534b38b>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, output_path)\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeamsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_gpt_conut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPTFConvModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeamsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_gpt_fconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;31m# except Exception as e:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m#    print(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/src/tester/beamsearch.py\u001b[0m in \u001b[0;36mgenerate_gpt_fconv\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_gpt_fconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0msrc_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net_input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BeamSearch' object has no attribute 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.version"
      ],
      "metadata": {
        "id": "a4nBg4Xp-gzm",
        "outputId": "3bac261c-4a03-4c19-b86b-d6c171017e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.13 (default, Apr 24 2022, 01:04:09) \\n[GCC 7.5.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbHeDUCRDyMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EleBCKmDyNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.version"
      ],
      "metadata": {
        "id": "6TvimaOTDza7",
        "outputId": "6292420d-3ae9-4f81-9973-e27d3ac47144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.13 (default, Apr 24 2022, 01:04:09) \\n[GCC 7.5.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model = torch.load(\"/content/data/models/gpt_f\")"
      ],
      "metadata": {
        "id": "hQhAtbOgwiRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y"
      ],
      "metadata": {
        "id": "Q7LmWyfCCa4u",
        "outputId": "47bc763a-e9be-4555-a855-bc484f95203c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [91.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,540 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,172 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,105 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,965 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,131 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,318 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,397 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,079 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.2 kB]\n",
            "Fetched 16.1 MB in 4s (3,809 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3.8"
      ],
      "metadata": {
        "id": "D3q2qJNACi0m",
        "outputId": "ae872d7c-5959-4271-eaa7-77379817de80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 4,695 kB of archives.\n",
            "After this operation, 18.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-minimal amd64 3.8.14-1+bionic1 [762 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8-minimal amd64 3.8.14-1+bionic1 [1,839 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-stdlib amd64 3.8.14-1+bionic1 [1,659 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8 amd64 3.8.14-1+bionic1 [435 kB]\n",
            "Fetched 4,695 kB in 4s (1,147 kB/s)\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.8-minimal_3.8.14-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.14-1+bionic1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../python3.8-minimal_3.8.14-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.14-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.8-stdlib_3.8.14-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.14-1+bionic1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../python3.8_3.8.14-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.14-1+bionic1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.14-1+bionic1) ...\n",
            "Setting up python3.8-minimal (3.8.14-1+bionic1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.14-1+bionic1) ...\n",
            "Setting up python3.8 (3.8.14-1+bionic1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8"
      ],
      "metadata": {
        "id": "wj8dKtddCrhw",
        "outputId": "73e0efba-e7e5-44a7-cbe1-d5dfb2919c41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: --install needs <link> <name> <path> <priority>\n",
            "\n",
            "Use 'update-alternatives --help' for program usage information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "gUm2MUMaCzmp",
        "outputId": "1414dd31-99ad-429f-f425-c3c0d985889f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --config python3"
      ],
      "metadata": {
        "id": "5fSLz6xGDGCq",
        "outputId": "b91f59ae-ceac-461f-fdb5-289f9b6ec6cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.7   2         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.7   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2"
      ],
      "metadata": {
        "id": "0hyDNRxtDYF6",
        "outputId": "5fd3cfec-8926-40b2-fd51-1a6c7b44b0e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1"
      ],
      "metadata": {
        "id": "5MWKOQl8D3R7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "eQvU0Q9gDi8L",
        "outputId": "f66d7c46-64cf-46a2-f0df-e1fdd763ee7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.version"
      ],
      "metadata": {
        "id": "yVv4dyTnD-b6",
        "outputId": "3ed5e89b-4b39-4c14-a7b9-9fb60fbcf183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.13 (default, Apr 24 2022, 01:04:09) \\n[GCC 7.5.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.version"
      ],
      "metadata": {
        "id": "KF9IhKH6EUxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --config python3"
      ],
      "metadata": {
        "id": "NCWq9UC-EIPb",
        "outputId": "42284782-844f-447b-f7e1-e637f738b938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.8   1         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.7   1         manual mode\n",
            "  3            /usr/bin/python3.8   1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.version"
      ],
      "metadata": {
        "id": "bT7Ikd2SEV-0",
        "outputId": "e1825069-c0b6-4624-d6bd-665a2dee2bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.13 (default, Apr 24 2022, 01:04:09) \\n[GCC 7.5.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --config python3"
      ],
      "metadata": {
        "id": "dXXEO3DlEZpe",
        "outputId": "90829ea5-d4e4-4504-8322-f16106db1a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.8   1         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.7   1         manual mode\n",
            "  3            /usr/bin/python3.8   1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.version"
      ],
      "metadata": {
        "id": "b-pb_CABEkyz",
        "outputId": "2ec1a72e-4d47-4779-df30-88bda7a2c597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.13 (default, Apr 24 2022, 01:04:09) \\n[GCC 7.5.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}